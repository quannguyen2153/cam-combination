{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from typing import Union, List\n",
    "from enum import Enum\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_grad_cam as cam\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget, ClassifierOutputSoftmaxTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
    "    deprocess_image, \\\n",
    "    preprocess_image\n",
    "class CAMType(Enum):\n",
    "    GRAD_CAM = cam.GradCAM\n",
    "    HI_RES_CAM = cam.HiResCAM\n",
    "    GRAD_CAM_ELEMENT_WISE = cam.GradCAMElementWise\n",
    "    ABLATION_CAM = cam.AblationCAM\n",
    "    X_GRAD_CAM = cam.XGradCAM\n",
    "    GRAD_CAM_PLUS_PLUS = cam.GradCAMPlusPlus\n",
    "    SCORE_CAM = cam.ScoreCAM\n",
    "    LAYER_CAM = cam.LayerCAM\n",
    "    EIGEN_CAM = cam.EigenCAM\n",
    "    EIGEN_GRAD_CAM = cam.EigenGradCAM\n",
    "    KPCA_CAM = cam.KPCA_CAM\n",
    "    RANDOM_CAM = cam.RandomCAM\n",
    "    FULL_GRAD = cam.FullGrad\n",
    "\n",
    "from typing import List, Callable\n",
    "\n",
    "def get_cam(cam_type: CAMType, model: torch.nn.Module, target_layers: torch.nn.Module):\n",
    "    cam_class = cam_type.value\n",
    "    return cam_class(model=model, target_layers=target_layers)\n",
    "\n",
    "def visualize(grayscale: torch.Tensor, rgb_img: np.ndarray):\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale, use_rgb=True)\n",
    "    plt.imshow(visualization)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def display_images_in_rows(rgb_img: np.ndarray, grayscale_list: List[torch.Tensor], labels: List[str]):\n",
    "    \"\"\"\n",
    "    Displays a list of images in rows, with each row containing up to max_images_per_row images.\n",
    "    \n",
    "    Args:\n",
    "        images (list of np.ndarray): List of images to display.\n",
    "        labels (list of str): List of labels for each image.\n",
    "        max_images_per_row (int): Maximum number of images per row (default is 4).\n",
    "    \"\"\"\n",
    "\n",
    "    images = [rgb_img]\n",
    "\n",
    "    for grayscale in grayscale_list:\n",
    "        images.append(show_cam_on_image(rgb_img, grayscale, use_rgb=True))\n",
    "\n",
    "    labels.insert(0, \"Image\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "    # Loop through the images and labels to display them\n",
    "    for ax, img, label in zip(axes, images, labels):\n",
    "        ax.imshow(img)  # Show the image\n",
    "        ax.set_title(label)  # Set the title\n",
    "        ax.axis('off')  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def execute_cam(\n",
    "        img_path: str,\n",
    "        model: torch.nn.Module,\n",
    "        target_layers: List[torch.nn.Module],\n",
    "        cam_type: CAMType,\n",
    "        targets: Union[List[ClassifierOutputTarget], None] = None,\n",
    "        visualization: bool = False,\n",
    "        output_path: Union[str, None] = None\n",
    "    ):\n",
    "        model_name = \"unknown\"\n",
    "        target_layer_name = \"unknown\"\n",
    "        try:\n",
    "            model_name = model._get_name()\n",
    "            target_layer_name = target_layers[0]._get_name()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(f\"Executing CAM on {model_name} with target layer {target_layer_name}:\")\n",
    "\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.float32(img) / 255\n",
    "        input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        # Forward to get target class if not specified\n",
    "        if not targets:\n",
    "            with torch.no_grad():\n",
    "                predicted_class = model(input_tensor).max(1)[-1]\n",
    "                targets = [ClassifierOutputTarget(predicted_class)]\n",
    "                print(predicted_class)\n",
    "                print(f\"Target class: {labels[str(predicted_class.item())][1]}\")\n",
    "\n",
    "        cam = get_cam(cam_type=cam_type, model=model, target_layers=target_layers)\n",
    "\n",
    "        # Generate the CAM\n",
    "        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "        # Overlay the CAM on the image\n",
    "        if visualization:\n",
    "            # Convert the PIL image to a NumPy array for visualization\n",
    "            rgb_img = np.array(rgb_img.resize((224, 224))) / 255.0  # Normalize the pixel values\n",
    "            \n",
    "            visualize(grayscale=grayscale_cam[0, :], rgb_img=rgb_img)\n",
    "\n",
    "            # Optionally, you can save the resulting CAM visualization\n",
    "            if output_path:\n",
    "                Image.fromarray((visualization * 255).astype(np.uint8)).save(output_path)\n",
    "                print(f\"Saved output image to {output_path}\")\n",
    "\n",
    "        return grayscale_cam, input_tensor\n",
    "\n",
    "labels = json.load(open(\"../pytorch_grad_cam/utils/imagenet_class_index.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerturbationConfidenceMetric:\n",
    "    def __init__(self, perturbation):\n",
    "        self.perturbation = perturbation\n",
    "\n",
    "    def __call__(self, input_tensor: torch.Tensor,\n",
    "                 cams: np.ndarray,\n",
    "                 targets: List[Callable],\n",
    "                 model: torch.nn.Module,\n",
    "                 return_visualization=False,\n",
    "                 return_diff=True):\n",
    "\n",
    "        if return_diff:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)\n",
    "                scores = [target(output).cpu().numpy()\n",
    "                          for target, output in zip(targets, outputs)]\n",
    "                scores = np.float32(scores)\n",
    "\n",
    "        batch_size = input_tensor.size(0)\n",
    "        perturbated_tensors = []\n",
    "        for i in range(batch_size):\n",
    "            cam = cams[i]\n",
    "            tensor = self.perturbation(input_tensor[i, ...].cpu(),\n",
    "                                       torch.from_numpy(cam))\n",
    "            tensor = tensor.to(input_tensor.device)\n",
    "            perturbated_tensors.append(tensor.unsqueeze(0))\n",
    "        perturbated_tensors = torch.cat(perturbated_tensors)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_after_imputation = model(perturbated_tensors)\n",
    "        scores_after_imputation = [\n",
    "            target(output).cpu().numpy() for target, output in zip(\n",
    "                targets, outputs_after_imputation)]\n",
    "        scores_after_imputation = np.float32(scores_after_imputation)\n",
    "\n",
    "        if return_diff:\n",
    "            result = scores_after_imputation - scores\n",
    "        else:\n",
    "            result = scores_after_imputation\n",
    "\n",
    "        if return_visualization:\n",
    "            return result, scores, scores_after_imputation, perturbated_tensors\n",
    "        else:\n",
    "            return result, scores, scores_after_imputation\n",
    "\n",
    "def multiply_tensor_with_cam(input_tensor: torch.Tensor,\n",
    "                             cam: torch.Tensor):\n",
    "    \"\"\" Multiply an input tensor (after normalization)\n",
    "        with a pixel attribution map\n",
    "    \"\"\"\n",
    "    return input_tensor * cam\n",
    "        \n",
    "class CamMultImageConfidenceChange(PerturbationConfidenceMetric):\n",
    "    def __init__(self):\n",
    "        super(CamMultImageConfidenceChange,\n",
    "              self).__init__(multiply_tensor_with_cam)\n",
    "        \n",
    "class DropInConfidence(CamMultImageConfidenceChange):\n",
    "    def __init__(self):\n",
    "        super(DropInConfidence, self).__init__()\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        scores, scores_before, scores_after = super(DropInConfidence, self).__call__(*args, **kwargs)\n",
    "        scores = -scores\n",
    "        return np.maximum(scores, 0) / scores_before * 100\n",
    "\n",
    "\n",
    "class IncreaseInConfidence(CamMultImageConfidenceChange):\n",
    "    def __init__(self):\n",
    "        super(IncreaseInConfidence, self).__init__()\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        scores, bef_score, scores_after = super(IncreaseInConfidence, self).__call__(*args, **kwargs)\n",
    "        return np.float32(scores > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose model & method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights=models.VGG16_Weights.DEFAULT).eval()\n",
    "target_layers = [model.features[28]]\n",
    "\n",
    "cam_type = CAMType.GRAD_CAM_PLUS_PLUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average drop & Average increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "input_folder = r\"C:\\Users\\HaPham\\Documents\\ThesisXAI\\Code\\CAM-combination\\ILSVRC2012\\ILSVRC2012_img_val\"\n",
    "imputated_folder = \"../imputated_images\"\n",
    "\n",
    "if os.path.exists(imputated_folder):\n",
    "    shutil.rmtree(imputated_folder)\n",
    "os.makedirs(imputated_folder)\n",
    "\n",
    "# Generate a list of image names within the specified range\n",
    "start_idx = 1\n",
    "end_idx = 50000\n",
    "num_images_to_sample = 1  # Adjust this to how many random images you want\n",
    "\n",
    "all_image_names = [\n",
    "    f\"ILSVRC2012_val_{i:08d}.JPEG\" for i in range(start_idx, end_idx + 1)\n",
    "]\n",
    "random_image_names = random.sample(all_image_names, num_images_to_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing CAM on VGG with target layer Conv2d:\n",
      "tensor([627])\n",
      "Target class: limousine\n",
      "Image: ILSVRC2012_val_00005250.JPEG\n",
      "Confidence 100% img: [[0.5408003]]\n",
      "Confidence 0% img: [[0.00023759]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cam_type = CAMType.GRAD_CAM\n",
    "cam_metric = CamMultImageConfidenceChange()\n",
    "drop_in_conf_metric = DropInConfidence()\n",
    "increase_in_conf_metric = IncreaseInConfidence()\n",
    "imputated_folder = \"../imputated_images\"\n",
    "for filename in random_image_names:\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    gray_scale_original, input_tensor = execute_cam(img_path=img_path, model=model, target_layers=target_layers, cam_type=cam_type)\n",
    "\n",
    "    gray_scale = np.zeros_like(gray_scale_original)\n",
    "\n",
    "    # Load and preprocess the image for CAM overlay\n",
    "    rgb_img = Image.open(img_path).convert('RGB')\n",
    "    rgb_img = np.array(rgb_img.resize((224, 224))) / 255.0\n",
    "    img_saliency = show_cam_on_image(rgb_img, gray_scale[0, :], use_rgb=True)\n",
    "\n",
    "    # Calculate predicted class and confidence score change\n",
    "    predicted_class = model(input_tensor).max(1)[-1]\n",
    "    # targets = [ClassifierOutputTarget(predicted_class)]\n",
    "    targets = [ClassifierOutputSoftmaxTarget(predicted_class)]\n",
    "    scores, scores_before, scores_after, visualizations = cam_metric(\n",
    "        input_tensor, gray_scale, targets, model, return_visualization=True\n",
    "    )\n",
    "\n",
    "    # Process the visualization for display and scoring\n",
    "    score = scores[0]\n",
    "    visualization = visualizations[0].cpu().numpy().transpose((1, 2, 0))\n",
    "    visualization = deprocess_image(visualization)\n",
    "\n",
    "    # Save the visualization\n",
    "    # Image.fromarray(visualization).save(os.path.join(imputated_folder, filename))\n",
    "    # Print individual results\n",
    "    print(f\"Image: {filename}\")\n",
    "    print(f\"Confidence 100% img: {scores_before}\")\n",
    "    print(f\"Confidence 0% img: {scores_after}\")\n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing CAM on VGG with target layer Conv2d:\n",
      "tensor([627])\n",
      "Target class: limousine\n",
      "Image: ILSVRC2012_val_00005250.JPEG\n",
      "AUC: 0.29279508025956597\n",
      "Average AUC: 0.29279508025956597\n"
     ]
    }
   ],
   "source": [
    "cam_type = CAMType.GRAD_CAM\n",
    "cam_metric = CamMultImageConfidenceChange()\n",
    "drop_in_conf_metric = DropInConfidence()\n",
    "increase_in_conf_metric = IncreaseInConfidence()\n",
    "imputated_folder = \"../imputated_images_insertion\"\n",
    "\n",
    "count = 0\n",
    "sum_auc = 0\n",
    "for filename in random_image_names:\n",
    "    confidences = []\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    gray_scale_original, input_tensor = execute_cam(img_path=img_path, model=model, target_layers=target_layers, cam_type=cam_type)\n",
    "\n",
    "    for i in range(100,-1,-1):\n",
    "        if(i == 100):\n",
    "            gray_scale = np.zeros_like(gray_scale_original)\n",
    "        else:\n",
    "            gray_scale = gray_scale_original.copy()\n",
    "            threshold = np.percentile(gray_scale, i)\n",
    "            gray_scale = gray_scale >= threshold\n",
    "\n",
    "        # Load and preprocess the image for CAM overlay\n",
    "        rgb_img = Image.open(img_path).convert('RGB')\n",
    "        rgb_img = np.array(rgb_img.resize((224, 224))) / 255.0\n",
    "        img_saliency = show_cam_on_image(rgb_img, gray_scale[0, :], use_rgb=True)\n",
    "\n",
    "        # Calculate predicted class and confidence score change\n",
    "        predicted_class = model(input_tensor).max(1)[-1]\n",
    "        # targets = [ClassifierOutputTarget(predicted_class)]\n",
    "        targets = [ClassifierOutputSoftmaxTarget(predicted_class)]\n",
    "        scores, scores_before, scores_after, visualizations = cam_metric(\n",
    "            input_tensor, gray_scale, targets, model, return_visualization=True\n",
    "        )\n",
    "\n",
    "        # Process the visualization for display and scoring\n",
    "        # score = scores[0]\n",
    "        # visualization = visualizations[0].cpu().numpy().transpose((1, 2, 0))\n",
    "        # visualization = deprocess_image(visualization)\n",
    "\n",
    "        # Save the visualization\n",
    "        # Image.fromarray(visualization).save(os.path.join(imputated_folder, f\"{os.path.splitext(filename)[0]}_{i}{os.path.splitext(filename)[1]}\"))\n",
    "        confidences.append(scores_after)\n",
    "        \n",
    "        # Print individual results\n",
    "        # print(f\"Image: {filename}\")\n",
    "        # print(f\"Step: {i}\\tConfidence: {scores_after}\")\n",
    "        # print(\"----------------------------------------\")\n",
    "    confidences = np.array(confidences).flatten()\n",
    "    confidences = (confidences - confidences.min()) / (confidences.max() - confidences.min())\n",
    "    fraction_revealed = np.linspace(0, 1, len(confidences))\n",
    "    auc = np.trapz(confidences, fraction_revealed)\n",
    "    count += 1\n",
    "    sum_auc += auc\n",
    "    print(f\"Image: {filename}\")\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "print(f\"Average AUC: {sum_auc/count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing CAM on VGG with target layer Conv2d:\n",
      "tensor([627])\n",
      "Target class: limousine\n",
      "Image: ILSVRC2012_val_00005250.JPEG\n",
      "AUC: 0.039899476889791424\n",
      "Average AUC: 0.039899476889791424\n"
     ]
    }
   ],
   "source": [
    "cam_type = CAMType.GRAD_CAM\n",
    "cam_metric = CamMultImageConfidenceChange()\n",
    "drop_in_conf_metric = DropInConfidence()\n",
    "increase_in_conf_metric = IncreaseInConfidence()\n",
    "imputated_folder = \"../imputated_images_deletion\"\n",
    "\n",
    "count = 0\n",
    "sum_auc = 0\n",
    "for filename in random_image_names:\n",
    "    confidences = []\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    gray_scale_original, input_tensor = execute_cam(img_path=img_path, model=model, target_layers=target_layers, cam_type=cam_type)\n",
    "\n",
    "    for i in range(100,-1,-1):\n",
    "\n",
    "        if(i == 0):\n",
    "            gray_scale = np.zeros_like(gray_scale_original)\n",
    "        else:\n",
    "            gray_scale = gray_scale_original.copy()\n",
    "            threshold = np.percentile(gray_scale, i)\n",
    "            gray_scale = gray_scale <= threshold\n",
    "\n",
    "        # Load and preprocess the image for CAM overlay\n",
    "        rgb_img = Image.open(img_path).convert('RGB')\n",
    "        rgb_img = np.array(rgb_img.resize((224, 224))) / 255.0\n",
    "        img_saliency = show_cam_on_image(rgb_img, gray_scale[0, :], use_rgb=True)\n",
    "\n",
    "        # Calculate predicted class and confidence score change\n",
    "        predicted_class = model(input_tensor).max(1)[-1]\n",
    "        # targets = [ClassifierOutputTarget(predicted_class)]\n",
    "        targets = [ClassifierOutputSoftmaxTarget(predicted_class)]\n",
    "        scores, scores_before, scores_after, visualizations = cam_metric(\n",
    "            input_tensor, gray_scale, targets, model, return_visualization=True\n",
    "        )\n",
    "\n",
    "        # Process the visualization for display and scoring\n",
    "        # score = scores[0]\n",
    "        # visualization = visualizations[0].cpu().numpy().transpose((1, 2, 0))\n",
    "        # visualization = deprocess_image(visualization)\n",
    "\n",
    "        # Save the visualization\n",
    "        # Image.fromarray(visualization).save(os.path.join(imputated_folder, filename))\n",
    "        # Image.fromarray(visualization).save(os.path.join(imputated_folder, f\"{os.path.splitext(filename)[0]}_{i}{os.path.splitext(filename)[1]}\"))\n",
    "        confidences.append(scores_after)\n",
    "\n",
    "        # Print individual results\n",
    "        # print(f\"Image: {filename}\")\n",
    "        # print(f\"Step: {i}\\tConfidence: {scores_after}\")\n",
    "        # print(\"----------------------------------------\")\n",
    "    confidences = np.array(confidences).flatten()\n",
    "    confidences = (confidences - confidences.min()) / (confidences.max() - confidences.min())\n",
    "    fraction_revealed = np.linspace(0, 1, len(confidences))\n",
    "    auc = np.trapz(confidences, fraction_revealed)\n",
    "    count += 1\n",
    "    sum_auc += auc\n",
    "    print(f\"Image: {filename}\")\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "print(f\"Average AUC: {auc/count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad CAM ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing CAM on VGG with target layer Conv2d:\n",
      "tensor([627])\n",
      "Target class: limousine\n",
      "Image: ILSVRC2012_val_00005250.JPEG\n",
      "AUC: 0.3155109561456038\n",
      "Average AUC: 0.3155109561456038\n"
     ]
    }
   ],
   "source": [
    "cam_type = CAMType.GRAD_CAM_PLUS_PLUS\n",
    "cam_metric = CamMultImageConfidenceChange()\n",
    "drop_in_conf_metric = DropInConfidence()\n",
    "increase_in_conf_metric = IncreaseInConfidence()\n",
    "imputated_folder = \"../imputated_images_insertion\"\n",
    "\n",
    "count = 0\n",
    "sum_auc = 0\n",
    "for filename in random_image_names:\n",
    "    confidences = []\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    gray_scale_original, input_tensor = execute_cam(img_path=img_path, model=model, target_layers=target_layers, cam_type=cam_type)\n",
    "\n",
    "    for i in range(100,-1,-1):\n",
    "        if(i == 100):\n",
    "            gray_scale = np.zeros_like(gray_scale_original)\n",
    "        else:\n",
    "            gray_scale = gray_scale_original.copy()\n",
    "            threshold = np.percentile(gray_scale, i)\n",
    "            gray_scale = gray_scale >= threshold\n",
    "\n",
    "        # Load and preprocess the image for CAM overlay\n",
    "        rgb_img = Image.open(img_path).convert('RGB')\n",
    "        rgb_img = np.array(rgb_img.resize((224, 224))) / 255.0\n",
    "        img_saliency = show_cam_on_image(rgb_img, gray_scale[0, :], use_rgb=True)\n",
    "\n",
    "        # Calculate predicted class and confidence score change\n",
    "        predicted_class = model(input_tensor).max(1)[-1]\n",
    "        # targets = [ClassifierOutputTarget(predicted_class)]\n",
    "        targets = [ClassifierOutputSoftmaxTarget(predicted_class)]\n",
    "        scores, scores_before, scores_after, visualizations = cam_metric(\n",
    "            input_tensor, gray_scale, targets, model, return_visualization=True\n",
    "        )\n",
    "\n",
    "        # Process the visualization for display and scoring\n",
    "        # score = scores[0]\n",
    "        # visualization = visualizations[0].cpu().numpy().transpose((1, 2, 0))\n",
    "        # visualization = deprocess_image(visualization)\n",
    "\n",
    "        # Save the visualization\n",
    "        # Image.fromarray(visualization).save(os.path.join(imputated_folder, f\"{os.path.splitext(filename)[0]}_{i}{os.path.splitext(filename)[1]}\"))\n",
    "        confidences.append(scores_after)\n",
    "        \n",
    "        # Print individual results\n",
    "        # print(f\"Image: {filename}\")\n",
    "        # print(f\"Step: {i}\\tConfidence: {scores_after}\")\n",
    "        # print(\"----------------------------------------\")\n",
    "    confidences = np.array(confidences).flatten()\n",
    "    confidences = (confidences - confidences.min()) / (confidences.max() - confidences.min())\n",
    "    fraction_revealed = np.linspace(0, 1, len(confidences))\n",
    "    auc = np.trapz(confidences, fraction_revealed)\n",
    "    count += 1\n",
    "    sum_auc += auc\n",
    "    print(f\"Image: {filename}\")\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "print(f\"Average AUC: {sum_auc/count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing CAM on VGG with target layer Conv2d:\n",
      "tensor([627])\n",
      "Target class: limousine\n",
      "Image: ILSVRC2012_val_00005250.JPEG\n",
      "AUC: 0.037077789985323364\n",
      "Average AUC: 0.037077789985323364\n"
     ]
    }
   ],
   "source": [
    "cam_type = CAMType.GRAD_CAM_PLUS_PLUS\n",
    "cam_metric = CamMultImageConfidenceChange()\n",
    "drop_in_conf_metric = DropInConfidence()\n",
    "increase_in_conf_metric = IncreaseInConfidence()\n",
    "imputated_folder = \"../imputated_images_deletion\"\n",
    "\n",
    "count = 0\n",
    "sum_auc = 0\n",
    "for filename in random_image_names:\n",
    "    confidences = []\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "    gray_scale_original, input_tensor = execute_cam(img_path=img_path, model=model, target_layers=target_layers, cam_type=cam_type)\n",
    "\n",
    "    for i in range(100,-1,-1):\n",
    "\n",
    "        if(i == 0):\n",
    "            gray_scale = np.zeros_like(gray_scale_original)\n",
    "        else:\n",
    "            gray_scale = gray_scale_original.copy()\n",
    "            threshold = np.percentile(gray_scale, i)\n",
    "            gray_scale = gray_scale <= threshold\n",
    "\n",
    "        # Load and preprocess the image for CAM overlay\n",
    "        rgb_img = Image.open(img_path).convert('RGB')\n",
    "        rgb_img = np.array(rgb_img.resize((224, 224))) / 255.0\n",
    "        img_saliency = show_cam_on_image(rgb_img, gray_scale[0, :], use_rgb=True)\n",
    "\n",
    "        # Calculate predicted class and confidence score change\n",
    "        predicted_class = model(input_tensor).max(1)[-1]\n",
    "        # targets = [ClassifierOutputTarget(predicted_class)]\n",
    "        targets = [ClassifierOutputSoftmaxTarget(predicted_class)]\n",
    "        scores, scores_before, scores_after, visualizations = cam_metric(\n",
    "            input_tensor, gray_scale, targets, model, return_visualization=True\n",
    "        )\n",
    "\n",
    "        # Process the visualization for display and scoring\n",
    "        # score = scores[0]\n",
    "        # visualization = visualizations[0].cpu().numpy().transpose((1, 2, 0))\n",
    "        # visualization = deprocess_image(visualization)\n",
    "\n",
    "        # Save the visualization\n",
    "        # Image.fromarray(visualization).save(os.path.join(imputated_folder, filename))\n",
    "        # Image.fromarray(visualization).save(os.path.join(imputated_folder, f\"{os.path.splitext(filename)[0]}_{i}{os.path.splitext(filename)[1]}\"))\n",
    "        confidences.append(scores_after)\n",
    "\n",
    "        # Print individual results\n",
    "        # print(f\"Image: {filename}\")\n",
    "        # print(f\"Step: {i}\\tConfidence: {scores_after}\")\n",
    "        # print(\"----------------------------------------\")\n",
    "    confidences = np.array(confidences).flatten()\n",
    "    confidences = (confidences - confidences.min()) / (confidences.max() - confidences.min())\n",
    "    fraction_revealed = np.linspace(0, 1, len(confidences))\n",
    "    auc = np.trapz(confidences, fraction_revealed)\n",
    "    count += 1\n",
    "    sum_auc += auc\n",
    "    print(f\"Image: {filename}\")\n",
    "    print(f\"AUC: {auc}\")\n",
    "\n",
    "print(f\"Average AUC: {auc/count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score-cam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
